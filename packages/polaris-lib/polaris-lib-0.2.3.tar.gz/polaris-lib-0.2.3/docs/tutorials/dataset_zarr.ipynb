{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39b58e71",
   "metadata": {},
   "source": [
    "# Creating datasets with zarr\n",
    "\n",
    "<div class=\"admonition abstract highlight\">\n",
    "    <p class=\"admonition-title\">In short</p>\n",
    "    <p>This tutorial shows how to create datasets with more advanced data-modalities through the .zarr format.</p>\n",
    "</div>\n",
    "\n",
    "## Pointer columns\n",
    "\n",
    "Not all data might fit the tabular format, e.g. images or conformers. In that case, we have _pointer_ columns. Pointer columns do not contain the data itself, but rather store a reference to an external file from which the content can be loaded.\n",
    "\n",
    "For now, we only support `.zarr` files as references. To learn more about `.zarr`, visit their documentation. Their [tutorial](https://zarr.readthedocs.io/en/stable/tutorial.html) is a specifically good read to better understand the main features. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e154bb54",
   "metadata": {},
   "source": [
    "### Dummy example\n",
    "For the sake of simplicity, let's assume we have just two datapoints. We will use this to demonstrate the idea behind pointer columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e201379",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr\n",
    "import platformdirs\n",
    "\n",
    "import numpy as np\n",
    "import datamol as dm\n",
    "import pandas as pd\n",
    "\n",
    "SAVE_DIR = dm.fs.join(platformdirs.user_cache_dir(appname=\"polaris-tutorials\"), \"002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07442028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a single image and save it to a .zarr directory\n",
    "images = np.random.random((2, 64, 64, 3))\n",
    "\n",
    "train_path = dm.fs.join(SAVE_DIR, \"single_train.zarr\")\n",
    "zarr.save(train_path, images[0])\n",
    "\n",
    "test_path = dm.fs.join(SAVE_DIR, \"single_test.zarr\")\n",
    "zarr.save(test_path, images[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16543db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.DataFrame(\n",
    "    {\n",
    "        \"images\": [train_path, test_path],  # Instead of the content, we specify paths\n",
    "        \"target\": np.random.random(2),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a257b09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from polaris.dataset import Dataset, ColumnAnnotation\n",
    "\n",
    "dataset = Dataset(\n",
    "    table=table,\n",
    "    # To indicate that we are dealing with a pointer column here,\n",
    "    # we need to annotate the column.\n",
    "    annotations={\"images\": ColumnAnnotation(is_pointer=True)},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2524c795",
   "metadata": {},
   "source": [
    "Note how the table does not contain the image data, but rather stores a path. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19a39fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/cas/.cache/polaris-tutorials/002/single_train.zarr'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.table.loc[0, \"images\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c051877",
   "metadata": {},
   "source": [
    "To load the data that is being pointed to, you can simply use the `Dataset.get_data()` utility method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8189f312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.get_data(col=\"images\", row=0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17aaff10",
   "metadata": {},
   "source": [
    "Creating a benchmark and the associated `Subset` objects will automatically do so! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f1c8766",
   "metadata": {},
   "outputs": [],
   "source": [
    "from polaris.benchmark import SingleTaskBenchmarkSpecification\n",
    "\n",
    "benchmark = SingleTaskBenchmarkSpecification(\n",
    "    dataset=dataset,\n",
    "    input_cols=\"images\",\n",
    "    target_cols=\"target\",\n",
    "    metrics=\"mean_absolute_error\",\n",
    "    split=([0], [1]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a0c635c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "train, test = benchmark.get_train_test_split()\n",
    "\n",
    "for x, y in train:\n",
    "    # At this point, the content is loaded from the path specified in the table\n",
    "    print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d2e77d",
   "metadata": {},
   "source": [
    "## Creating datasets from `.zarr` arrays\n",
    "\n",
    "While the above example works, creating the table with all paths from scratch is time-consuming when datasets get large. Instead, you can also automatically parse a `.zarr` hierarchy into the expected tabular data structure. \n",
    "\n",
    "A little more about zarr: A `.zarr` file can contain groups and arrays, where each group can again contain groups and arrays. Each array can be saved as one or multiple chunks. Additional user attributes (for any array or group) are saved as JSON files.\n",
    "\n",
    "Within Polaris:\n",
    "\n",
    "1. Each subgroup of the root group corresponds to a single column.\n",
    "2. Each subgroup can contain:\n",
    "    - A single array with all datapoints.\n",
    "    - A single array per datapoint.\n",
    "3. Additional meta-data is saved to the user attributes of the root group.\n",
    "4. The indices are required to be integers.\n",
    "\n",
    "To better explain what this works, let's look at two examples corresponding to the two cases in point 2 above. \n",
    "\n",
    "### A single array _per_ data point\n",
    "In this first example we will create a zarr array _per_ data point. The structure of the zarr will look like: \n",
    "\n",
    "```\n",
    "/\n",
    "  column_a/\n",
    "      array_1\n",
    "      array_2\n",
    "      ...\n",
    "      array_N\n",
    "```\n",
    "\n",
    "and as we will see, this will get parsed into\n",
    "\n",
    "| column_a                             |\n",
    "| ------------------------------------ |\n",
    "| /path/to/root.zarr/column_a/array_1  |\n",
    "| /path/to/root.zarr/column_a/array_2  |\n",
    "|                  ...                 |\n",
    "| /path/to/root.zarr/column_a/array_N  |\n",
    "\n",
    "\n",
    "<div class=\"admonition info highlight\">\n",
    "    <p class=\"admonition-title\">Note</p>\n",
    "    <p>Notice dataset now no longer stores the content of the array itself, but rather a reference to the array.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04f47190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first create some dummy dataset with 1000 64x64 \"images\"\n",
    "images = np.random.random((1000, 64, 64, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55e55f3",
   "metadata": {},
   "source": [
    "To be able to use these images in Polaris, we need to save them in the zarr hierarchy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4d4d32e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = dm.fs.join(SAVE_DIR, \"zarr\", \"archive_multi.zarr\")\n",
    "\n",
    "with zarr.open(path, \"w\") as root:\n",
    "    with root.create_group(\"images\") as group:\n",
    "        for i, arr in enumerate(images):\n",
    "            # If you're saving an array per datapoint,\n",
    "            # the name of the array needs to be an integer\n",
    "            group.array(i, arr)\n",
    "\n",
    "    # he root directory can furthermore contain all additional meta-data in its user attributes.\n",
    "    root.attrs[\"name\"] = \"dummy_image_dataset\"\n",
    "    root.attrs[\"description\"] = \"Randomly generated 64x64 images\"\n",
    "    root.attrs[\"source\"] = \"https://doi.org/xx.xxxx\"\n",
    "\n",
    "    # To ensure proper processing, it is important that we annotate the column.\n",
    "    # As this has to be JSON serializable, we create a dict instead of the object.\n",
    "    # Due to using Pydantic, this will work seamlessly.\n",
    "    root.attrs[\"annotations\"] = {\"images\": {\"is_pointer\": True}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0885513",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_zarr(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a7809e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.get_data(col=\"images\", row=0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6977165",
   "metadata": {},
   "source": [
    "### A single array for _all_ datapoints \n",
    "Instead of having an array per datapoint, you might also batch all arrays in a single array. This could for example speed up compression.\n",
    "\n",
    "In this case, our zarr hierarchy will look like this: \n",
    "```\n",
    "/\n",
    "  column_a/\n",
    "      array\n",
    "```\n",
    "\n",
    "Which will get parsed into a table like: \n",
    "\n",
    "| column_a                             |\n",
    "| ------------------------------------ |\n",
    "| /path/to/root.zarr/column_a/array#1  |\n",
    "| /path/to/root.zarr/column_a/array#2  |\n",
    "|                 ...                  |\n",
    "| /path/to/root.zarr/column_a/array#N  |\n",
    "\n",
    "<div class=\"admonition info highlight\">\n",
    "    <p class=\"admonition-title\">Note</p>\n",
    "    <p>Notice the # suffix in the path, which indicates the index at which the data-point is stored within the big array. </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12a06b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = dm.fs.join(SAVE_DIR, \"zarr\", \"archive_single.zarr\")\n",
    "\n",
    "with zarr.open(path, \"w\") as root:\n",
    "    with root.create_group(\"images\") as group:\n",
    "        group.array(\"data\", images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c7c11ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/cas/.cache/polaris-tutorials/002/zarr/archive_single.zarr//images/data#0'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.from_zarr(path)\n",
    "\n",
    "# The path refers to the original zarr directory we created in the above code block\n",
    "dataset.table.iloc[0][\"images\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8d1b42d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.get_data(col=\"images\", row=0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51493c81",
   "metadata": {},
   "source": [
    "## Saving the dataset\n",
    "\n",
    "We can still easily save the dataset. All the pointer columns will be automatically updated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1cd94077",
   "metadata": {},
   "outputs": [],
   "source": [
    "savedir = dm.fs.join(SAVE_DIR, \"json\")\n",
    "json_path = dataset.to_json(savedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5147684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/cas/.cache/polaris-tutorials/002/benchmark.json',\n",
       " '/home/cas/.cache/polaris-tutorials/002/single_train.zarr',\n",
       " '/home/cas/.cache/polaris-tutorials/002/dataset.json',\n",
       " '/home/cas/.cache/polaris-tutorials/002/table.parquet',\n",
       " '/home/cas/.cache/polaris-tutorials/002/zarr',\n",
       " '/home/cas/.cache/polaris-tutorials/002/single_test.zarr',\n",
       " '/home/cas/.cache/polaris-tutorials/002/json']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs = dm.fs.get_mapper(path).fs\n",
    "fs.ls(SAVE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bf6c19",
   "metadata": {},
   "source": [
    "Besides the `table.parquet` and `dataset.yaml`, we can now also see a `data` folder which stores the content for the additional content from the pointer columns. Instead, we might want to rather save as a single `.zarr` file. With the `array_mode` argument, we can choose between the two structures we outlined in this repository. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40e210fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "savedir = dm.fs.join(SAVE_DIR, \"zarr\")\n",
    "zarr_path = dataset.to_zarr(savedir, array_mode=\"single\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3801c96f",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33c25a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset.from_json(json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f7de196",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset.from_zarr(zarr_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72767ef2",
   "metadata": {},
   "source": [
    "The End. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
