{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4c2483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -e ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae91a7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip show cag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1acacf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cag.framework.annotator.pipeline.pipeline_base import Pipeline\n",
    "from cag.utils.config import Config\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857066a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure arangodb is up and running - Enter your credentials below\n",
    "my_config = Config(\n",
    "    url=\"http://127.0.0.1:8529\",\n",
    "    user=\"root\",\n",
    "    password=\"root\",\n",
    "    database=\"_system\",\n",
    "    graph=\"MyCagGraph\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cc35efa0",
   "metadata": {},
   "source": [
    "## Create your first CAG Annotation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c94e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extends the CAG Pipeline and implements the two methds: process_input and init_and_run\n",
    "class MyFirstPipeline(Pipeline):\n",
    "    def __post_init__(self):\n",
    "        print(\"In POST INIT\")\n",
    "        self.out_path = \"myfirstpipeline_output.csv\"\n",
    "        self.exec_transformer_based = False\n",
    "\n",
    "    # Code for preprocessing the input data before annotating. In this case here, we convert the nodes into a list of tuples.\n",
    "    # Each tuple contains the text of the node and the _key (the unique id of the node)\n",
    "    def process_input(self) -> list:\n",
    "        processed = []\n",
    "        for txt_node in tqdm(self.input):\n",
    "            processed.append((txt_node.text, {\"_key\": txt_node._key}))\n",
    "\n",
    "        return processed\n",
    "\n",
    "    def init_and_run(self):\n",
    "        if self.exec_transformer_based:\n",
    "            self.add_annotation_pipe(\n",
    "                name=\"sentencizer\",\n",
    "                save_output=False,\n",
    "                is_spacy=True,\n",
    "                is_native=True,\n",
    "            )\n",
    "            self.add_annotation_pipe(\n",
    "                name=\"EmotionPipeOrchestrator\", save_output=True, is_spacy=True\n",
    "            )\n",
    "            # self.add_annotation_pipe(\n",
    "            #    name=\"HedgePipeOrchestrator\", save_output=True, is_spacy=True\n",
    "            # )\n",
    "            self.add_annotation_pipe(\n",
    "                name=\"ToxicityPipeOrchestrator\",\n",
    "                save_output=True,\n",
    "                is_spacy=True,\n",
    "            )\n",
    "        else:\n",
    "            self.add_annotation_pipe(\n",
    "                name=\"tok2vec\",\n",
    "                save_output=False,\n",
    "                is_spacy=True,\n",
    "                is_native=True,\n",
    "            )  # mandatory for NER\n",
    "            self.add_annotation_pipe(\n",
    "                name=\"NamedEntityPipeOrchestrator\",\n",
    "                save_output=True,\n",
    "                is_spacy=True,\n",
    "            )\n",
    "            self.add_annotation_pipe(\n",
    "                name=\"mpqa_parser\",\n",
    "                save_output=False,\n",
    "                is_spacy=True,\n",
    "                is_native=True,\n",
    "            )\n",
    "            self.add_annotation_pipe(\n",
    "                name=\"MpqaPipeOrchestrator\", save_output=True, is_spacy=True\n",
    "            )\n",
    "            self.add_annotation_pipe(\n",
    "                name=\"EmpathPipeOrchestrator\", save_output=True, is_spacy=True\n",
    "            )\n",
    "\n",
    "        self.init_pipe_stack()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "77b84341",
   "metadata": {},
   "source": [
    "## Initialize your first cag Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a1ca4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cag_pipeline = MyFirstPipeline(my_config)\n",
    "cag_pipeline.spacy_n_processors = 1  # In case you are using spacy pipe, this flag can be set to enable multiprocessing,\n",
    "# NOTE: If you are using spacy with transformer based feature, set the flag to 1 or else the pipeline will freeze (this is a spacy bug and not related to cag)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e9bf7c7a",
   "metadata": {},
   "source": [
    "## Fetch the TextNode and Annotate & Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f85ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Loop over your data, annotateA and save\n",
    "cag_pipeline.exec_transformer_based = False\n",
    "cag_pipeline.init_and_run()\n",
    "\n",
    "coll = cag_pipeline.database_config.db[\"TextNode\"]\n",
    "docs = coll.fetchAll(limit=300)\n",
    "fetched = len(docs)\n",
    "while docs is not None and len(docs) > 0:\n",
    "    ## annotate\n",
    "\n",
    "    # Set the INPUT - this will automatically call preprocess_input (make sure to implement it)\n",
    "    cag_pipeline.reset_input_output()\n",
    "    cag_pipeline.set_input(docs)\n",
    "\n",
    "    cag_pipeline.annotate()\n",
    "    cag_pipeline.save()\n",
    "\n",
    "    cag_pipeline.reset_input_output()\n",
    "    print(f\"Processed {fetched} docs\")\n",
    "    docs = coll.fetchAll(limit=100, skip=fetched)\n",
    "    fetched = fetched + len(docs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ca599894",
   "metadata": {},
   "source": [
    "### Transformer based Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b585ef9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cag_pipeline.exec_transformer_based = True\n",
    "cag_pipeline.out_path = \"transformer_based_features.csv\"\n",
    "cag_pipeline.init_and_run()\n",
    "coll = cag_pipeline.database_config.db[\"TextNode\"]\n",
    "docs = coll.fetchAll(limit=100)\n",
    "fetched = len(docs)\n",
    "while docs is not None and len(docs) > 0:\n",
    "    ## annotate\n",
    "\n",
    "    # Set the INPUT - this will automatically call preprocess_input (make sure to implement it)\n",
    "    cag_pipeline.reset_input_output()\n",
    "    cag_pipeline.set_input(docs)\n",
    "\n",
    "    cag_pipeline.annotate()\n",
    "    cag_pipeline.save()\n",
    "\n",
    "    print(f\"Processed {fetched} docs\")\n",
    "    docs = coll.fetchAll(limit=100, skip=fetched)\n",
    "    fetched = fetched + len(docs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "9023573090597f88184b7bdb602b12409def018d86092a20fba49938f13d4f2a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
