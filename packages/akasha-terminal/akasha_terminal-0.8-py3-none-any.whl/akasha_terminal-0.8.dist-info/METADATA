Metadata-Version: 2.1
Name: akasha-terminal
Version: 0.8
Summary: document QA package using langchain and chromadb
Home-page: https://gitlab-devops.iii.org.tw/root/qaiii-1
Author: chih chuan chang
Author-email: ccchang@iii.org.tw
Requires-Python: >=3.8
License-File: License
Requires-Dist: pypdf
Requires-Dist: langchain (==0.0.345)
Requires-Dist: chromadb (==0.4.14)
Requires-Dist: openai (==0.27)
Requires-Dist: tiktoken
Requires-Dist: lark (==1.1.7)
Requires-Dist: scikit-learn (<1.3.0)
Requires-Dist: jieba (==0.42.1)
Requires-Dist: sentence-transformers (==2.2.2)
Requires-Dist: torch (==2.0.1)
Requires-Dist: transformers (==4.31.0)
Requires-Dist: llama-cpp-python (==0.2.6)
Requires-Dist: auto-gptq (==0.3.1)
Requires-Dist: tqdm (==4.65.0)
Requires-Dist: docx2txt (==0.8)
Requires-Dist: rouge (==1.0.1)
Requires-Dist: rouge-chinese (==1.0.3)
Requires-Dist: bert-score (==0.3.13)
Requires-Dist: click
Requires-Dist: tokenizers (==0.13.3)
Requires-Dist: streamlit (==1.28.2)
Requires-Dist: streamlit-option-menu (==0.3.6)
Requires-Dist: opencc (==1.1.1)

Akasha simplifies document-based Question Answering (QA) by harnessing the power of Large Language Models to accurately answer your queries while searching through your provided documents.
With Akasha, you have the flexibility to choose from a variety of language models, embedding models, and search types. Adjusting these parameters is straightforward, allowing you to optimize your approach and discover the most effective methods for obtaining accurate answers from Large Language Models.
